{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import copy\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from operator import itemgetter\n",
    "from itertools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df : pd.DataFrame, folder : str, file_name : str, filetype : str) -> None:\n",
    "    \n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        \n",
    "        if filetype == 'csv':\n",
    "            \n",
    "            df.to_csv(os.path.join(folder, 'preprocessed_' + file_name), index = False) \n",
    "    \n",
    "    elif isinstance(df, dict):\n",
    "        \n",
    "        for key in df.keys():\n",
    "            \n",
    "            if isinstance(df[key], pd.DataFrame):\n",
    "                \n",
    "                df[key].to_csv(os.path.join(folder, 'preprocessed_' + str(key)), index = False) \n",
    "                \n",
    "            else:\n",
    "                \n",
    "                print('datatype is not dataframe')\n",
    "                return False    \n",
    "    else:\n",
    "                \n",
    "        print('df wrong type argument')\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "\n",
    "    @staticmethod\n",
    "    def to_datetime(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        if not isinstance(data.index, pd.DatetimeIndex):\n",
    "            data.index = pd.to_datetime(data['periodtime_1m'].astype('str'), format='%Y%m%d%H%M')\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def sorting_df(data : pd.DataFrame, col_name  = ['periodtime_1m']) -> pd.DataFrame :\n",
    "        \n",
    "        return data.sort_values(by= col_name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_missing_index(data : pd.DataFrame, start_tm: str, end_tm: str, freq = '1T') -> pd.DataFrame :\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            start_index = str(min(data.periodtime_1m.values))\n",
    "            end_index =  str(max(data.periodtime_1m.values))\n",
    "            \n",
    "        except AttributeError:\n",
    "            \n",
    "            print(' no {} in data_column'.format('periodtime_1m'))\n",
    "\n",
    "        if not isinstance(data.index, pd.DatetimeIndex):\n",
    "           \n",
    "            data.index = pd.to_datetime(data['periodtime_1m'].astype('str'), format='%Y%m%d%H%M')\n",
    "            \n",
    "        if len(pd.date_range(start_index, end_index , freq= freq)) == len(data.index):\n",
    "            print('processing_fill',data.index)     \n",
    "            return data.loc[start_tm:end_tm]\n",
    "           \n",
    "\n",
    "        else:\n",
    "                            \n",
    "            full_time_data = pd.DataFrame(index=pd.date_range(start_index , end_index , freq='1T'), columns=['tmp'])\n",
    "            data = data.combine_first(full_time_data)\n",
    "            return data.loc[start_tm:end_tm]\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_interpolation( data, freq = '1T'):\n",
    "        \n",
    "        data.interpolate(method = 'values',inplace = True, limit_area=None)\n",
    "        data.bfill(inplace =True)\n",
    "        data.ffill(inplace =True)\n",
    "        if Preprocessor.checkNa(data):\n",
    "            raise ValueError('Na exist')\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    @staticmethod\n",
    "    def resampling(data : pd.DataFrame, start_tm, end_tm, sampling_time = '5T') -> pd.DataFrame:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            start_tm = str(min(data.periodtime_1m.values))\n",
    "            end_tm =  str(max(data.periodtime_1m.values))\n",
    "            \n",
    "        except AttributeError:\n",
    "            \n",
    "            print(' no {} in data_column'.format('periodtime_1m'))\n",
    "                \n",
    "        if not isinstance(data.index, pd.DatetimeIndex):\n",
    "            \n",
    "            data = Preprocessor.to_datetime(data)\n",
    "            \n",
    "        return data.loc[pd.date_range(start_tm, end_tm , freq = sampling_time)]\n",
    "    @staticmethod\n",
    "    def moving_average(data : pd.DataFrame, minutes = 3):\n",
    "         \n",
    "        col_name= 'prod_MA' + '_' + str(minutes)\n",
    "        \n",
    "        data.loc[:, col_name] = data.prod_tt.iloc[:].rolling(window = minutes, min_periods=1).mean()\n",
    "        \n",
    "        return data\n",
    "    @staticmethod\n",
    "    def convert_speed_to_time(data:pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        data.loc[:,'real_length'] = data['real_tt']*data['real_ts']/3.6\n",
    "        col_tt = data.loc[: , [\"prod_tt_0\",'prod_tt_1',\"prod_tt_2\"]]\n",
    "        col_ts = data.loc[: ,[ \"prod_ts_0\",'prod_ts_1',\"prod_ts_2\"]]\n",
    "        data['past_prod_ts_mean'] =  col_ts.mean(axis=1)\n",
    "        data['past_prod_tt_mean_1'] =  col_tt.mean(axis=1)\n",
    "        data['past_prod_tt_mean_2'] = (data['real_length'] / data['past_prod_ts_mean'])*3.6\n",
    "        return data\n",
    "    @staticmethod\n",
    "    def checkNa(data:pd.DataFrame) -> bool:\n",
    "        if (data['real_tt'].isnull().values.any()) or (data['prod_tt'].isnull().values.any()):\n",
    "            print(np.where(np.asanyarray(np.isnan(data))))\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tr_dataset_manger():\n",
    "    \n",
    "    \"\"\"\n",
    "        class 설명 : 데이터 셋 만드는 코드\n",
    "        \n",
    "        argument 설명 :\n",
    "        \n",
    "            header_flags : 읽어드리는 csv file에 header 여부 \n",
    "        \n",
    "            multi_feature_flags {\n",
    "                \n",
    "                True > featrue 를 travel_speed + congestion (prod)\n",
    "                False > feature를 travel_speed 단일 피쳐\n",
    "                \n",
    "                }\n",
    "\n",
    "            load_cate : 'express' > 고속도로 데이터\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, data_path, file_name, header_flags = False, multi_feature_flags = True, load_cate = 'express'):\n",
    "        \n",
    "            \n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.traffic_data_path = os.path.join(data_path, file_name)        \n",
    "        self.header_flags = header_flags\n",
    "        self.column_dict = None\n",
    "        self.data = None\n",
    "        self.multi_feature_flags = multi_feature_flags\n",
    "\n",
    "        ## data 기간 정해주는 부분 \n",
    "        self.info = {\n",
    "\n",
    "            'start_tm': '201902090000',\n",
    "            'end_tm' :  '202005312359'\n",
    "        }\n",
    "        # csv파일에 헤더가 없을 경우 만들어주는 부분 (header_flags argument와 연동)\n",
    "        self.column_dict = {\n",
    "\n",
    "            'col_1' : 'periodtime_1m',\n",
    "            'col_2' : 'periodtime_5m',\n",
    "            'col_3' : 'tsdlinkid',\n",
    "            'col_4' : 'nexttsdlinkid',\n",
    "            'col_5' : 'representlength',\n",
    "            'col_6' : 'roadclass',\n",
    "            'col_7' : 'linkclass',\n",
    "            'col_8' : 'congestionclass',\n",
    "            'col_9' : 'real_ts',\n",
    "            'col_10' : 'real_tt',\n",
    "            'col_11' : 'real_pc',\n",
    "            'col_12' : 'real_con',\n",
    "            'col_13' : 'real_na_code',\n",
    "            'col_14' : 'prod_ts',\n",
    "            'col_15' : 'prod_tt',\n",
    "            'col_16' : 'prod_pc',\n",
    "            'col_17' : 'prod_con',\n",
    "            'col_18' : 'prod_ret',\n",
    "            'col_19' : 'prod_na_code',\n",
    "            'col_20' : 'pat_ts',\n",
    "            'col_21' : 'pat_tt',\n",
    "            'col_22' : 'pat_accum_pc',\n",
    "            'col_23' : 'pat_con',\n",
    "            'col_24' : 'patuseflag',\n",
    "            'col_25' : 'pat_na_code',\n",
    "            'col_26' : 'periodtype',\n",
    "            'col_27' : 'tm',\n",
    "            'col_28' : 'dt'\n",
    "        }\n",
    "            \n",
    "    def read_file(self):\n",
    "        \n",
    "        if self.header_flags ==False:\n",
    "            \n",
    "            data = pd.read_csv(self.traffic_data_path, names = list(self.column_dict.values()))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            data = pd.read_csv(self.traffic_data_path)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    def preprocessing_data(self):\n",
    "\n",
    "        ## 수정 중  return 결과물이 npz 파일로 return 되게끔 수정 필요 \n",
    "        \n",
    "        result_prod = np.array([])\n",
    "        result_real  = np.array([]) \n",
    "        result_prod_con = np.array([])\n",
    "        result_real_con = np.array([])\n",
    "        result_jam_flags = np.array([])\n",
    "        \n",
    "        \n",
    "        data = self.read_file()\n",
    "        self.preprocessed_data_dict = {}\n",
    "        \n",
    "        idx_dict = pd.read_csv(os.path.join(self.data_path,'tsd_mapping.csv'))[['idx','tsdlink_id']].set_index('idx')\\\n",
    "        ['tsdlink_id'].to_dict()\n",
    "        \n",
    "        for i, key in enumerate(idx_dict.keys()):\n",
    "\n",
    "        \n",
    "            tsd = idx_dict[key]\n",
    "            file_name = 'preprocessed_' + str(tsd) +'_' + '.csv'\n",
    "\n",
    "            if data.dtypes['tsdlinkid'] != 'int':\n",
    "\n",
    "                data['tsdlinkid'] = data['tsdlinkid'].astype('int')\n",
    "\n",
    "            tmp_data = copy.deepcopy(data.loc[(data.tsdlinkid == tsd)])\n",
    "            \"\"\" \n",
    "\n",
    "            추후 PREPROCESSOR 클래스 매소드의 일부는 데이더 추출 과정에서 big-query나 spark / hive로 작업해오는게 더 나음\n",
    "\n",
    "            \"\"\"\n",
    "            tmp_data = Preprocessor.sorting_df(tmp_data)\n",
    "            tmp_data = Preprocessor.fill_missing_index(tmp_data,self.info['start_tm'], self.info['end_tm'])\n",
    "            tmp_data = Preprocessor.linear_interpolation(tmp_data)\n",
    "            tmp_data = Preprocessor.resampling(tmp_data, self.info['start_tm'], self.info['end_tm'])\n",
    "            tmp_data = Preprocessor.moving_average(tmp_data)\n",
    "\n",
    "            tmp_data['row_idx'] = np.arange(len(tmp_data))\n",
    "            tmp_data['row_idx'] = tmp_data['row_idx'].astype('int')\n",
    "            \n",
    "            tmp_data['lagged_real_con'] = tmp_data.real_con.shift(-1)\n",
    "            tmp_data['lagged2_real_con'] = tmp_data.real_con.shift(-2)\n",
    "            tmp_data['jam_flags'] = np.where((tmp_data.real_con != 1.0) | (tmp_data.lagged_real_con != 1.0)\\\n",
    "                                              | (tmp_data.lagged2_real_con != 1.0), 1, 0)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if Preprocessor.checkNa(tmp_data):\n",
    "\n",
    "                print('{} : NA exists'.format(key))\n",
    "                print()\n",
    "                return tmp_data\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n",
      "processing_fill DatetimeIndex(['2019-01-01 00:00:00', '2019-01-01 00:01:00',\n",
      "               '2019-01-01 00:02:00', '2019-01-01 00:03:00',\n",
      "               '2019-01-01 00:04:00', '2019-01-01 00:05:00',\n",
      "               '2019-01-01 00:06:00', '2019-01-01 00:07:00',\n",
      "               '2019-01-01 00:08:00', '2019-01-01 00:09:00',\n",
      "               ...\n",
      "               '2020-05-31 23:50:00', '2020-05-31 23:51:00',\n",
      "               '2020-05-31 23:52:00', '2020-05-31 23:53:00',\n",
      "               '2020-05-31 23:54:00', '2020-05-31 23:55:00',\n",
      "               '2020-05-31 23:56:00', '2020-05-31 23:57:00',\n",
      "               '2020-05-31 23:58:00', '2020-05-31 23:59:00'],\n",
      "              dtype='datetime64[ns]', name='periodtime_1m', length=744480, freq=None)\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = '../data/raw_data/'\n",
    "file_name = 'traffic_express.csv'\n",
    "data_manger = Tr_dataset_manger(data_path = raw_data_path , file_name = file_name, multi_feature_flags = True,\\\n",
    "                                load_cate = 'express')\n",
    "data = data_manger.preprocessing_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data.loc['2019-02-09 00:15:00':]['real_tt'].isnull().values.any()) or (data.loc['2019-02-09 00:15:00':]['prod_tt'].isnull().values.any()):\n",
    "    print(np.where(np.asanyarray(np.isnan(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-712d3948cb20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodtime_1m</th>\n",
       "      <th>periodtime_5m</th>\n",
       "      <th>tsdlinkid</th>\n",
       "      <th>nexttsdlinkid</th>\n",
       "      <th>representlength</th>\n",
       "      <th>roadclass</th>\n",
       "      <th>linkclass</th>\n",
       "      <th>congestionclass</th>\n",
       "      <th>real_ts</th>\n",
       "      <th>real_tt</th>\n",
       "      <th>...</th>\n",
       "      <th>patuseflag</th>\n",
       "      <th>pat_na_code</th>\n",
       "      <th>periodtype</th>\n",
       "      <th>tm</th>\n",
       "      <th>dt</th>\n",
       "      <th>prod_MA_3</th>\n",
       "      <th>row_idx</th>\n",
       "      <th>lagged_real_con</th>\n",
       "      <th>lagged2_real_con</th>\n",
       "      <th>jam_flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-09 00:00:00</th>\n",
       "      <td>201902090000</td>\n",
       "      <td>201902090000</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20190209</td>\n",
       "      <td>32.470394</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-09 00:05:00</th>\n",
       "      <td>201902090005</td>\n",
       "      <td>201902090005</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20190209</td>\n",
       "      <td>34.804497</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-09 00:10:00</th>\n",
       "      <td>201902090010</td>\n",
       "      <td>201902090010</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20190209</td>\n",
       "      <td>35.582534</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-09 00:15:00</th>\n",
       "      <td>201902090015</td>\n",
       "      <td>201902090015</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>44.432163</td>\n",
       "      <td>27.547611</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20190209</td>\n",
       "      <td>36.995091</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-09 00:20:00</th>\n",
       "      <td>201902090020</td>\n",
       "      <td>201902090020</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34.317158</td>\n",
       "      <td>35.667290</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20190209</td>\n",
       "      <td>33.182753</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31 23:35:00</th>\n",
       "      <td>202005312335</td>\n",
       "      <td>202005312335</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43.770800</td>\n",
       "      <td>28.292900</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>20200531</td>\n",
       "      <td>30.264567</td>\n",
       "      <td>137659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31 23:40:00</th>\n",
       "      <td>202005312340</td>\n",
       "      <td>202005312340</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>40.282900</td>\n",
       "      <td>30.742600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>20200531</td>\n",
       "      <td>29.316667</td>\n",
       "      <td>137660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31 23:45:00</th>\n",
       "      <td>202005312345</td>\n",
       "      <td>202005312345</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>40.804700</td>\n",
       "      <td>30.349500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>20200531</td>\n",
       "      <td>28.641767</td>\n",
       "      <td>137661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31 23:50:00</th>\n",
       "      <td>202005312350</td>\n",
       "      <td>202005312350</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.111400</td>\n",
       "      <td>29.436100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>20200531</td>\n",
       "      <td>29.775400</td>\n",
       "      <td>137662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31 23:55:00</th>\n",
       "      <td>202005312355</td>\n",
       "      <td>202005312355</td>\n",
       "      <td>5295152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43.418100</td>\n",
       "      <td>28.522700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>20200531</td>\n",
       "      <td>30.444433</td>\n",
       "      <td>137663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137664 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     periodtime_1m  periodtime_5m  tsdlinkid  nexttsdlinkid  \\\n",
       "2019-02-09 00:00:00   201902090000   201902090000    5295152            NaN   \n",
       "2019-02-09 00:05:00   201902090005   201902090005    5295152            NaN   \n",
       "2019-02-09 00:10:00   201902090010   201902090010    5295152            NaN   \n",
       "2019-02-09 00:15:00   201902090015   201902090015    5295152            NaN   \n",
       "2019-02-09 00:20:00   201902090020   201902090020    5295152            NaN   \n",
       "...                            ...            ...        ...            ...   \n",
       "2020-05-31 23:35:00   202005312335   202005312335    5295152            NaN   \n",
       "2020-05-31 23:40:00   202005312340   202005312340    5295152            NaN   \n",
       "2020-05-31 23:45:00   202005312345   202005312345    5295152            NaN   \n",
       "2020-05-31 23:50:00   202005312350   202005312350    5295152            NaN   \n",
       "2020-05-31 23:55:00   202005312355   202005312355    5295152            NaN   \n",
       "\n",
       "                     representlength  roadclass  linkclass  congestionclass  \\\n",
       "2019-02-09 00:00:00              340          5          1                4   \n",
       "2019-02-09 00:05:00              340          5          1                4   \n",
       "2019-02-09 00:10:00              340          5          1                4   \n",
       "2019-02-09 00:15:00              340          5          1                4   \n",
       "2019-02-09 00:20:00              340          5          1                4   \n",
       "...                              ...        ...        ...              ...   \n",
       "2020-05-31 23:35:00              344          5          1                4   \n",
       "2020-05-31 23:40:00              344          5          1                4   \n",
       "2020-05-31 23:45:00              344          5          1                4   \n",
       "2020-05-31 23:50:00              344          5          1                4   \n",
       "2020-05-31 23:55:00              344          5          1                4   \n",
       "\n",
       "                       real_ts    real_tt  ...  patuseflag  pat_na_code  \\\n",
       "2019-02-09 00:00:00        NaN        NaN  ...         NaN          1.0   \n",
       "2019-02-09 00:05:00        NaN        NaN  ...         NaN          1.0   \n",
       "2019-02-09 00:10:00        NaN        NaN  ...         NaN          1.0   \n",
       "2019-02-09 00:15:00  44.432163  27.547611  ...         NaN          1.0   \n",
       "2019-02-09 00:20:00  34.317158  35.667290  ...         NaN          1.0   \n",
       "...                        ...        ...  ...         ...          ...   \n",
       "2020-05-31 23:35:00  43.770800  28.292900  ...         1.0          1.0   \n",
       "2020-05-31 23:40:00  40.282900  30.742600  ...         1.0          1.0   \n",
       "2020-05-31 23:45:00  40.804700  30.349500  ...         1.0          1.0   \n",
       "2020-05-31 23:50:00  42.111400  29.436100  ...         1.0          1.0   \n",
       "2020-05-31 23:55:00  43.418100  28.522700  ...         1.0          1.0   \n",
       "\n",
       "                     periodtype  tm        dt  prod_MA_3  row_idx  \\\n",
       "2019-02-09 00:00:00           5   0  20190209  32.470394        0   \n",
       "2019-02-09 00:05:00           5   0  20190209  34.804497        1   \n",
       "2019-02-09 00:10:00           5   0  20190209  35.582534        2   \n",
       "2019-02-09 00:15:00           5   0  20190209  36.995091        3   \n",
       "2019-02-09 00:20:00           5   0  20190209  33.182753        4   \n",
       "...                         ...  ..       ...        ...      ...   \n",
       "2020-05-31 23:35:00           5  23  20200531  30.264567   137659   \n",
       "2020-05-31 23:40:00           5  23  20200531  29.316667   137660   \n",
       "2020-05-31 23:45:00           5  23  20200531  28.641767   137661   \n",
       "2020-05-31 23:50:00           5  23  20200531  29.775400   137662   \n",
       "2020-05-31 23:55:00           5  23  20200531  30.444433   137663   \n",
       "\n",
       "                     lagged_real_con  lagged2_real_con  jam_flags  \n",
       "2019-02-09 00:00:00              NaN               NaN          1  \n",
       "2019-02-09 00:05:00              NaN               1.0          1  \n",
       "2019-02-09 00:10:00              1.0               1.0          1  \n",
       "2019-02-09 00:15:00              1.0               1.0          0  \n",
       "2019-02-09 00:20:00              1.0               1.0          0  \n",
       "...                              ...               ...        ...  \n",
       "2020-05-31 23:35:00              1.0               1.0          0  \n",
       "2020-05-31 23:40:00              1.0               1.0          0  \n",
       "2020-05-31 23:45:00              1.0               1.0          0  \n",
       "2020-05-31 23:50:00              1.0               1.0          1  \n",
       "2020-05-31 23:55:00              1.0               1.0          1  \n",
       "\n",
       "[137664 rows x 33 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.interpolate(method = 'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
